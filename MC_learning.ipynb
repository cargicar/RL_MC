{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.signal\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/carloscardona/opt/anaconda3/envs/RL/lib/python3.9/site-packages/gym/__init__.py'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EpsilonGreedyPolicy(Q, epsilon, state):\n",
    "    # The smaller the epsilon the greedier the agent:\n",
    "    if np.random.random() > epsilon: \n",
    "        return np.argmax(Q[state]) \n",
    "    else:\n",
    "        #action = np.random.randint(0, env.action_space.n) \n",
    "        return  np.random.randint(0, env.action_space.n) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monte carlo \n",
    "class MC(object):\n",
    "    def __init__(self, env, num_states, num_actions, gamma=1, eps=0.1, eps_decay=0.9999, first_visit=True,\n",
    "                  render=True, max_iter=100000):\n",
    "        self.env=env\n",
    "        self.num_states = num_states\n",
    "        self.num_actions = num_actions\n",
    "        self.first_visit = first_visit\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        self.eps_decay = eps_decay\n",
    "        self.max_iter=max_iter\n",
    "        self.render=render\n",
    "\n",
    "        self.Q = np.random.uniform(low = -1, high = 1, \n",
    "                          size =(self.num_states, self.num_actions))\n",
    "        self.Q_num = np.zeros((self.num_states, self.num_actions))\n",
    "        self.visited_num = np.zeros((self.num_states, self.num_actions))\n",
    "    ###################################################################################################\n",
    "        # one episode containing max_iterations (200 is the max of iteration in the montaincar by default)\n",
    "    def update_Q(self):\n",
    "        \n",
    "        obs = self.env.reset()    \n",
    "        policy = partial(EpsilonGreedyPolicy, self.Q, self.eps)\n",
    "\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        states = []\n",
    "    \n",
    "        for _ in range(self.max_iter):\n",
    "            state_idx = []\n",
    "            flatten_index=0\n",
    "            for ob, lower, upper, num in zip(obs, lower_bounds, upper_bounds, num_states):\n",
    "                state =int(num * (ob - lower) / (upper- lower) )\n",
    "                if state >= num:\n",
    "                    state = num - 1\n",
    "                if state < 0:\n",
    "                    state = 0\n",
    "                state_idx.append(state)\n",
    "\n",
    "            flatten_index=np.ravel_multi_index(state_idx, num_states)\n",
    "        \n",
    "            action = policy(flatten_index)\n",
    "            \n",
    "            # save state and action taken in this step\n",
    "            actions.append(action)\n",
    "            states.append(flatten_index)\n",
    "\n",
    "            if self.render:\n",
    "                env.render()\n",
    "                #time.sleep(0.03)\n",
    "            # take an action    \n",
    "            [obs, reward, done, info] = env.step(action)\n",
    "            # Save the reward after the action has been taken\n",
    "            rewards.append(reward)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "        ############################################################################\n",
    "        updated_states = set()\n",
    "        discounted_rewards=scipy.signal.lfilter([1],[1,-self.gamma], np.array(rewards)[::-1], axis=0)[::-1]\n",
    "        \n",
    "        for state, action, disc_rew in zip(states, actions, discounted_rewards):\n",
    "\n",
    "            if self.first_visit:\n",
    "                if state in updated_states:\n",
    "                    continue\n",
    "\n",
    "                updated_states.add(state)\n",
    "\n",
    "            # incremental averaging\n",
    "            \n",
    "            # count the number of state-=action pairs visited in this episode\n",
    "            self.Q_num[state, action] += 1\n",
    "            \n",
    "            # compute the average aproximation for the Q-tensor from this episode\n",
    "            self.Q[state, action] += (disc_rew - self.Q[state, action]) / self.Q_num[state, action]\n",
    "            self.visited_num[state, action] += 1\n",
    "            rewards_in_episode= np.sum(np.array(rewards))\n",
    "\n",
    "        self.eps *= self.eps_decay\n",
    "\n",
    "        return rewards_in_episode, self.Q\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> <font size=4> By default, the montain-car enviroment is capped at 200 iterations by episode, which is not ideal for Monte Carlo, which computes a better average for greater samples per episode. This is because by the law of large numbers, the average reward of a given episode will get closer to the actual average the larger the sample space. To increase the number of iteration in a single episode, we can use a nice feature of open ai gym, which is the \"register\", that allow us to alter some default parameters of the enviorements and define our own: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.envs.register(\n",
    "    id='MountainCarExtraLong-v0',\n",
    "    entry_point='gym.envs.classic_control:MountainCarEnv',\n",
    "    max_episode_steps=500,\n",
    "    reward_threshold=475.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-08 12:42:13.356 python[74035:2091204] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fd0b78b53e0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2021-10-08 12:42:13.357 python[74035:2091204] Warning: Expected min height of view: (<NSButton: 0x7fd0b8f70430>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2021-10-08 12:42:13.361 python[74035:2091204] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fd0ba926710>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2021-10-08 12:42:13.363 python[74035:2091204] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fd0b816e1a0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 1 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 2 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 3 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 4 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 5 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 6 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 7 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 8 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 9 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 10 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 11 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 12 reward: -413.0\n",
      "Average regards0.0\n",
      "Iteration 13 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 14 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 15 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 16 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 17 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 18 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 19 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 20 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 21 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 22 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 23 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 24 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 25 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 26 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 27 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 28 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 29 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 30 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 31 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 32 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 33 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 34 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 35 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 36 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 37 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 38 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 39 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 40 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 41 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 42 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 43 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 44 reward: -452.0\n",
      "Average regards0.0\n",
      "Iteration 45 reward: -358.0\n",
      "Average regards0.0\n",
      "Iteration 46 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 47 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 48 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 49 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 50 reward: -377.0\n",
      "Average regards0.0\n",
      "Iteration 51 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 52 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 53 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 54 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 55 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 56 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 57 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 58 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 59 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 60 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 61 reward: -474.0\n",
      "Average regards0.0\n",
      "Iteration 62 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 63 reward: -383.0\n",
      "Average regards0.0\n",
      "Iteration 64 reward: -375.0\n",
      "Average regards0.0\n",
      "Iteration 65 reward: -279.0\n",
      "Average regards0.0\n",
      "Iteration 66 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 67 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 68 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 69 reward: -346.0\n",
      "Average regards0.0\n",
      "Iteration 70 reward: -444.0\n",
      "Average regards0.0\n",
      "Iteration 71 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 72 reward: -333.0\n",
      "Average regards0.0\n",
      "Iteration 73 reward: -407.0\n",
      "Average regards0.0\n",
      "Iteration 74 reward: -462.0\n",
      "Average regards0.0\n",
      "Iteration 75 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 76 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 77 reward: -478.0\n",
      "Average regards0.0\n",
      "Iteration 78 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 79 reward: -265.0\n",
      "Average regards0.0\n",
      "Iteration 80 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 81 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 82 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 83 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 84 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 85 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 86 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 87 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 88 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 89 reward: -213.0\n",
      "Average regards0.0\n",
      "Iteration 90 reward: -175.0\n",
      "Average regards0.0\n",
      "Iteration 91 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 92 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 93 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 94 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 95 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 96 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 97 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 98 reward: -500.0\n",
      "Average regards0.0\n",
      "Iteration 99 reward: -500.0\n",
      "Average regards0.0\n"
     ]
    }
   ],
   "source": [
    "#load the enviroment\n",
    "env = gym.make('MountainCarExtraLong-v0')\n",
    "\n",
    "# define the (to be discretized) action-state space\n",
    "num_actions = env.action_space.n   # number of actions of the enviroment, in montain car we have\n",
    "                                   # three actions, acelerate left, right and not acelerate. \n",
    "num_states = [36, 28]              # number of discrete states we want. This can be chance, but increasing it will\n",
    "                                   # also increase the computation cost. \n",
    "lower_bounds = np.array([-12, -7]) # lower value for the position and the velocity (don't mind the units :P)\n",
    "upper_bounds = np.array([6, 7])    # upper value for the position and the velocity\n",
    "\n",
    "\n",
    "state_space_dim = np.prod(np.array(num_states)) # dimension of the state space\n",
    "\n",
    "#  MC(env, num_states, num_actions, gamma=1, eps=0.1, eps_decay=0.9999, first_visit=True,\n",
    "#                  render=True, max_iter=100000):\n",
    "mc = MC(env,state_space_dim , num_actions,eps=0.3, first_visit=True)\n",
    "\n",
    "num_episodes = 100\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    rewards_in_episode, Q= mc.update_Q()\n",
    "    print(\"Iteration \" + str(i) + \" reward: \" + str(rewards_in_episode))\n",
    "    print(\"Average regards\" + str(rewards[i]) )\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards)\n",
    "plt.title('rewards over episodes')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('test.npy', 'wb') as f:\n",
    "#     np.save(f, np.array([1, 2]))\n",
    "#     np.save(f, np.array([1, 3]))\n",
    "# with open('test.npy', 'rb') as f:\n",
    "#     a = np.load(f)\n",
    "#     b = np.load(f)\n",
    "with open('Q_MC_1.npy', 'wb') as f:\n",
    "    np.save(f, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> <font size=4>Now that we have a succeding version of the Q-tensor, we can just loaded and use without need to running the whole Monte Carlo computation again. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import time \n",
    "from functools import partial\n",
    "\n",
    "gym.envs.register(\n",
    "    id='MountainCarExtraLong-v0',\n",
    "    entry_point='gym.envs.classic_control:MountainCarEnv',\n",
    "    max_episode_steps=500,\n",
    "    reward_threshold=475.0,\n",
    ")\n",
    "env = gym.make('MountainCarExtraLong-v0')\n",
    "\n",
    "def EpsilonGreedyPolicy(Q, epsilon, state):\n",
    "\n",
    "    if np.random.random() > epsilon: # CC. Given an epsilon, if epsilon is smaller than a randoom number \n",
    "                                         # between 0 and 1\n",
    "        return np.argmax(Q[state]) \n",
    "    else:\n",
    "        #action = np.random.randint(0, env.action_space.n) \n",
    "        return  np.random.randint(0, env.action_space.n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Q_MC_1.npy', 'rb') as f:\n",
    "    Q = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "num_steps = 2000\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "num_actions = env.action_space.n\n",
    "num_states = [36, 28]\n",
    "lower_bounds = np.array([-12, -7])\n",
    "upper_bounds = np.array([6, 7])\n",
    "\n",
    "for _ in range(num_steps):\n",
    "    state_idx = []\n",
    "    flatten_index=0\n",
    "    for ob, lower, upper, num in zip(obs, lower_bounds, upper_bounds, num_states):\n",
    "        state =int(num * (ob - lower) / (upper- lower) )\n",
    "        if state >= num:\n",
    "            state = num - 1\n",
    "        if state < 0:\n",
    "            state = 0\n",
    "        state_idx.append(state)\n",
    "    \n",
    "    flatten_index=np.ravel_multi_index(state_idx, num_states)\n",
    "    policy = partial(EpsilonGreedyPolicy, Q, 0)\n",
    "    action = policy(flatten_index)\n",
    "    # apply the action\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    \n",
    "    # Render the env\n",
    "    env.viewer = None\n",
    "    env.render()\n",
    "\n",
    "    # Wait a bit before the next frame unless you want to see a crazy fast video\n",
    "    time.sleep(0.001)\n",
    "    \n",
    "    # If the epsiode is up, then start another one\n",
    "    if done:\n",
    "        obs= env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reinforcement_Learning",
   "language": "python",
   "name": "reinforcement_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
